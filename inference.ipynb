{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ef9dcce-1d05-46dc-979c-a91378a8237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (RobertaConfig, RobertaModel, RobertaTokenizer, RobertaForCausalLM)\n",
    "\n",
    "from models import CustomEncoderDecoderModel\n",
    "from data_collator import DataCollatorForSeq2Seq\n",
    "from trainer import CustomTrainer, CustomTrainingArguments\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "from typing import Optional, Any, Union, List, Dict, Tuple\n",
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "228295af-ce67-47ac-b429-44ba49d1b6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EncoderDecoderModel\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from transformers import (RobertaConfig, RobertaModel, RobertaTokenizer, RobertaForCausalLM)\n",
    "from trainer import CustomTrainer, CustomTrainingArguments\n",
    "from data_collator import DataCollatorForSeq2Seq\n",
    "\n",
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef85cba-cbe8-4962-b813-8542b9f293f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a036f29b-88e7-4369-a3f5-3d0ef81d29d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## experiment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a92413-aba3-48d5-9fee-b792f88f2bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"set random seed.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "set_seed(4321)\n",
    "\n",
    "DECODER_CLASSES = {'roberta-base': (RobertaForCausalLM, RobertaConfig)}\n",
    "\n",
    "DATASET_PATH = \"dataset-ifttt-zenodo\"\n",
    "os.path.exists(DATASET_PATH)\n",
    "\n",
    "MODEL = \"roberta\"\n",
    "assert(MODEL in ('roberta', 'codebert'))\n",
    "\n",
    "EXPERIMENT = \"chen\"\n",
    "assert(EXPERIMENT in ('chen', 'mi', 'merged'))\n",
    "\n",
    "OUTPUT_DIR = \"rob2rand_chen\"\n",
    "\n",
    "LOAD_FROM_CKPT = True\n",
    "if LOAD_FROM_CKPT:\n",
    "    ckpt = \"models/rob2rand_chen/checkpoint-35000\"\n",
    "    assert(os.path.exists(ckpt) == True)\n",
    "DEBUG = None\n",
    "DATA_NUM = 8 if DEBUG else None\n",
    "NUM_BEAMS = 10\n",
    "RETURN_TOP_K = 10\n",
    "\n",
    "DO_INFERENCE_GOLD=True\n",
    "DO_INFERENCE_NOISY=True\n",
    "DO_INFERENCE_TEST_FIELD=False\n",
    "\n",
    "# setting for the tokenizer\n",
    "MAX_INPUT_LENGTH = 100 \n",
    "MAX_TARGET_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8399754b-a5c0-4f30-8c49-cff88d427866",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = CustomTrainingArguments(\n",
    "    f\"{OUTPUT_DIR}\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500 if not DEBUG else 1,\n",
    "    logging_steps=500 if not DEBUG else 1,\n",
    "    do_eval=True,\n",
    "    do_train=True,\n",
    "    learning_rate=5e-6,\n",
    "    per_device_train_batch_size=64 if not (DO_INFERENCE_GOLD or DO_INFERENCE_NOISY or DO_INFERENCE_TEST_FIELD) else 32,\n",
    "    per_device_eval_batch_size=64 if not (DO_INFERENCE_GOLD or DO_INFERENCE_NOISY or DO_INFERENCE_TEST_FIELD) else 32,\n",
    "    weight_decay=0.0,\n",
    "    warmup_steps=1000,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=50 if not DEBUG else 3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    optim='adamw_torch',\n",
    "    generation_num_beams=NUM_BEAMS if NUM_BEAMS else None,\n",
    "    generation_max_length=MAX_TARGET_LENGTH,\n",
    "    num_return_sequences=RETURN_TOP_K,\n",
    "    metrics_to_check=[('eval_bleu', True), \n",
    "                      ('eval_bleu_em', True),\n",
    "                      ('eval_em', True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ab4273-c296-4029-8d82-94789718d798",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4529d1b0-3f7a-4f10-8b96-fcfaef8e7cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_path(root=DATASET_PATH, exp=EXPERIMENT):\n",
    "    if exp==\"chen\":\n",
    "        train_path = os.path.join(root, \"ready-train-chen-only/train-chen.pkl\")\n",
    "        val_path = os.path.join(root, \"ready-train-val-noisy/validation-noisy.pkl\")\n",
    "        gold_path = os.path.join(root, \"ready-test-clean/test_gold_clean.pkl\")\n",
    "        noisy_path = os.path.join(root, \"ready-test-clean/test_intel_clean.pkl\")\n",
    "    return {\"train\": train_path,\n",
    "            \"val\": val_path,\n",
    "            \"gold\": gold_path,\n",
    "            \"noisy\": noisy_path}\n",
    "\n",
    "path_dict = get_dataset_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6b8bf5a-cf5a-499c-aead-a3e00e3c91af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 45003 entries, 0 to 45005\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   source  45003 non-null  object\n",
      " 1   target  45003 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(path_dict=path_dict, number=None):\n",
    "    assert(type(path_dict)==dict)\n",
    "    df_dict = {}\n",
    "    for split, path in path_dict.items():\n",
    "        if number:\n",
    "            df_dict[split] = pd.read_pickle(path).sample(n=number, random_state=1234).copy()\n",
    "        else:\n",
    "            df_dict[split] = pd.read_pickle(path)\n",
    "    return df_dict\n",
    "\n",
    "if DATA_NUM:\n",
    "    df_dict = load_dataset(number=DATA_NUM)\n",
    "else:\n",
    "    df_dict = load_dataset()\n",
    "\n",
    "df_dict['train'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f37e6daa-55fb-40b5-9634-416caafd13ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dataset(df_dict=df_dict):\n",
    "    train = Dataset.from_pandas(df_dict['train']).remove_columns(['__index_level_0__'])\n",
    "    val = Dataset.from_pandas(df_dict['val']).remove_columns(['__index_level_0__'])\n",
    "    gold = Dataset.from_pandas(df_dict['gold']).remove_columns(['__index_level_0__'])\n",
    "    noisy = Dataset.from_pandas(df_dict['noisy']).remove_columns(['__index_level_0__'])\n",
    "    \n",
    "    return DatasetDict({'train':train,\n",
    "                        'val':val,\n",
    "                        'gold':gold,\n",
    "                        'noisy':noisy})\n",
    "\n",
    "dataset = convert_to_dataset()\n",
    "\n",
    "if DEBUG:\n",
    "    print(dataset.column_names)\n",
    "    print([dataset['train'][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d33513e-304b-4709-aef0-98f9733df4de",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "349e51e9-8684-4b10-8994-21143b7eb8a3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_tokenizer(model=MODEL):\n",
    "    if model == 'roberta':\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "    elif model == 'codebert':\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "    else:\n",
    "        raise ValueError(f\"Undefined model type\")\n",
    "    return tokenizer\n",
    "\n",
    "tokenizer = load_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "268058e0-e2b2-4eb3-99be-3447c78bf3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8814c700460d4d4387d0fd6140fc96be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=46.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9c325e458b47948bd2d077dc79b6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a144751d7747b69b71fa87b72cc486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c18227ca2348618cc4d15b7da84330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [ex for ex in examples[\"source\"]]\n",
    "    targets = [ex for ex in examples[\"target\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=MAX_INPUT_LENGTH, truncation=True, padding=False)\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=MAX_TARGET_LENGTH, truncation=True, padding=False)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")\n",
    "\n",
    "if DEBUG:\n",
    "    for item in tokenized_datasets['train'][:8]['input_ids']:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba289c8-e5e4-4716-b5f2-de1eb443be28",
   "metadata": {
    "tags": []
   },
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a63b2add-5b03-4f6c-86d3-8d1151f37186",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from models/rob2rand_chen/checkpoint-35000\n"
     ]
    }
   ],
   "source": [
    "if LOAD_FROM_CKPT:\n",
    "    model = EncoderDecoderModel.from_pretrained(ckpt)\n",
    "    print(f\"Loading from {ckpt}\")\n",
    "else:\n",
    "    model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"roberta-base\", \"roberta-base\", random_decoder=True, model_dict=DECODER_CLASSES)\n",
    "    print(\"Loading not from checkpoint\")\n",
    "    model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    model.config.vocab_size = model.config.decoder.vocab_size\n",
    "    model.config.architectures = \"EncoderDecoderModel\"\n",
    "    model.config.max_length = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1054ac1b-f520-490b-b451-a73302005d82",
   "metadata": {
    "tags": []
   },
   "source": [
    "## data collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf03a13a-63ca-4dfc-8085-e3e09a3a1ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "if DEBUG:\n",
    "    batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(1, 3)])\n",
    "    batch.keys()\n",
    "    print(batch[\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c4d7f8-2db2-4360-8312-1a9cec25f420",
   "metadata": {
    "tags": []
   },
   "source": [
    "# metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e03afeb-663d-4f0a-9db3-c1ca4a6769fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = load_metric(\"sacrebleu\")\n",
    "em = load_metric(\"exact_match\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    \n",
    "    def decode_preds(eval_preds):\n",
    "        preds, labels = eval_preds\n",
    "        # In case the model returns more than the prediction logits\n",
    "        if isinstance(preds, tuple):\n",
    "            preds = preds[0]\n",
    "\n",
    "        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "        # Replace -100s in the labels as we can't decode them\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        # Some simple post-processing\n",
    "        decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "        decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "        return decoded_preds, decoded_labels\n",
    "    \n",
    "    decoded_preds, decoded_labels = decode_preds(eval_preds)\n",
    "    \n",
    "    bleu_dict = bleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # decoded_preds = [pred[0] for pred in decoded_preds]\n",
    "    decoded_labels = [label[0] for label in decoded_labels]\n",
    "    em_dict = em.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {\"bleu\": bleu_dict[\"score\"],\n",
    "           \"em\": em_dict['exact_match'],\n",
    "           \"bleu_em\": (bleu_dict['score']+em_dict['exact_match'])/2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e2dbf6-d013-4b6c-9514-6ee7a41e0cba",
   "metadata": {
    "tags": []
   },
   "source": [
    "# custom trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3397d987-55a6-4452-b3d6-96d4ac73d63a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"val\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4368ba0a-df62-4f82-b065-9940eeebce5c",
   "metadata": {},
   "source": [
    "# result on latest ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4c1925a-62de-4437-b17c-7c180f7b9775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:530: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='126' max='91' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [91/91 04:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.07814013957977295,\n",
       " 'eval_bleu': 81.21997005616592,\n",
       " 'eval_em': 50.22452504317789,\n",
       " 'eval_bleu_em': 65.7222475496719,\n",
       " 'eval_runtime': 185.1399,\n",
       " 'eval_samples_per_second': 15.637,\n",
       " 'eval_steps_per_second': 0.492}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd423d5f-ba10-474c-b47e-dc2402562310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.01039204653352499,\n",
       " 'eval_bleu': 97.7771768701106,\n",
       " 'eval_em': 91.14754098360656,\n",
       " 'eval_bleu_em': 188.92471785371714,\n",
       " 'eval_runtime': 17.9924,\n",
       " 'eval_samples_per_second': 16.952,\n",
       " 'eval_steps_per_second': 0.278}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=tokenized_datasets['gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b003e94-652f-446a-a2a0-44f50323cdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.06291293352842331,\n",
       " 'eval_bleu': 85.8551097560776,\n",
       " 'eval_em': 53.18595578673602,\n",
       " 'eval_bleu_em': 139.0410655428136,\n",
       " 'eval_runtime': 47.1894,\n",
       " 'eval_samples_per_second': 16.296,\n",
       " 'eval_steps_per_second': 0.275}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=tokenized_datasets['noisy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e29463-462b-4717-9680-d1bbafa30cf1",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5164addb-eaf2-4b7a-975d-6e946b4b56f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_INFERENCE_GOLD:\n",
    "    INFERENCE_DIR_GOLD = f\"{ckpt}/inference/gold\"\n",
    "    if not os.path.exists(INFERENCE_DIR_GOLD):\n",
    "        os.makedirs(INFERENCE_DIR_GOLD)\n",
    "    trainer.inference(eval_dataset=tokenized_datasets['gold'], output_dir_inference=INFERENCE_DIR_GOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc3540d0-b8c9-42e2-a4ca-992df60d2920",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DO_INFERENCE_NOISY:\n",
    "    INFERENCE_DIR_NOISY = f\"{ckpt}/inference/noisy\"\n",
    "    if not os.path.exists(INFERENCE_DIR_NOISY):\n",
    "        os.makedirs(INFERENCE_DIR_NOISY)\n",
    "    trainer.inference(eval_dataset=tokenized_datasets['noisy'], output_dir_inference=INFERENCE_DIR_NOISY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d96a3-1598-468f-a91f-17db3b584922",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_INFERENCE_TEST_FIELD:\n",
    "    INFERENCE_DIR_TEST_FIELD = f\"{ckpt}/inference/test_field\"\n",
    "    if not os.path.exists(INFERENCE_DIR_TEST_FIELD):\n",
    "        os.makedirs(INFERENCE_DIR_TEST_FIELD)\n",
    "    trainer.inference(eval_dataset=tokenized_datasets['test_field'], output_dir_inference=INFERENCE_DIR_TEST_FIELD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
